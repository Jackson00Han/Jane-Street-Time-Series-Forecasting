{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import MAE  # 用 MAE 训练\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "\n",
    "# 项目内工具\n",
    "from pipeline.io import cfg, P, fs, storage_options, ensure_dir_local\n",
    "\n",
    "def _now(): \n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 工具函数 ----------\n",
    "def add_missing_flags_and_fill(df: pd.DataFrame, group_col: str, cont_cols: list[str]) -> tuple[list[str], pd.DataFrame]:\n",
    "    \"\"\"连续特征：添加 __isna 标记，组内 ffill，兜底 0 填充。\"\"\"\n",
    "    if not cont_cols:\n",
    "        return [], df\n",
    "    df = df.copy()\n",
    "    df[cont_cols] = df[cont_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    flags = []\n",
    "    g = df.groupby(group_col, observed=False)\n",
    "    for c in cont_cols:\n",
    "        flag = f\"{c}__isna\"\n",
    "        flags.append(flag)\n",
    "        df[flag] = df[c].isna().astype(\"int8\")\n",
    "        df[c] = g[c].ffill()\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "    return flags, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df51f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- 主流程 ----------\n",
    "\n",
    "print(f\"[{_now()}][tft] ===== start =====\")\n",
    "target_col = cfg[\"target\"]                 # 如 \"responder_6\"\n",
    "g_sym, g_date, g_time = cfg[\"keys\"]        # 如 (\"symbol_id\",\"date_id\",\"time_id\")\n",
    "weight_col = cfg[\"weight\"]\n",
    "TIME_SORT = cfg[\"sorts\"].get(\"time_major\", [g_date, g_time, g_sym])\n",
    "\n",
    "# 1) 选择特征列（示例：你后续替换为真实列表）\n",
    "time_features = [\"time_pos\", \"time_sin\", \"time_cos\", \"time_bucket\"]\n",
    "base_features   = [\"feature_36\", \"feature_06\"]                 # TODO: 放入你的真实特征集合\n",
    "resp_his_feats  = [\"responder_5_prevday_std\", \"responder_3_prevday_std\", \"responder_4_prev_tail_d1\"]  # 示例\n",
    "feat_his_feats  = [\"feature_08__ewm5\", \"feature_53__rstd3\"]           # 示例\n",
    "feature_cols = list(dict.fromkeys(base_features + resp_his_feats + feat_his_feats))\n",
    "\n",
    "need_cols = list(dict.fromkeys(cfg[\"keys\"] + [weight_col] + [target_col] + time_features + feature_cols))\n",
    "\n",
    "# 2) 读 panel（Lazy） & 构 grid\n",
    "panel_dir = P(\"az\", cfg[\"paths\"].get(\"panel_shards\", \"panel_shards\"))\n",
    "glob_pat  = f\"{panel_dir}/*.parquet\"\n",
    "if not fs.glob(glob_pat.replace(\"az://\", \"\")):\n",
    "    raise FileNotFoundError(f\"No parquet shards under: {glob_pat}\")\n",
    "lf = pl.scan_parquet(glob_pat, storage_options=storage_options)\n",
    "\n",
    "grid_path = P(\"local\", \"tft/panel/grid_timeidx.parquet\")\n",
    "if not Path(grid_path).exists():\n",
    "    lf_grid = (\n",
    "        lf.select([g_date, g_time]).unique()\n",
    "        .sort([g_date, g_time])\n",
    "        .with_row_index(\"time_idx\")\n",
    "        .with_columns(pl.col(\"time_idx\").cast(pl.Int64))\n",
    "    )\n",
    "    ensure_dir_local(Path(grid_path).parent.as_posix())\n",
    "    lf_grid.collect(streaming=True).write_parquet(grid_path, compression=\"zstd\")\n",
    "    print(f\"[{_now()}][tft] grid saved -> {grid_path}\")\n",
    "grid_lazy = pl.scan_parquet(grid_path)\n",
    "\n",
    "# 全局 time_idx 连续性（安全检查）\n",
    "grid_df = grid_lazy.select([g_date, g_time, \"time_idx\"]).collect()\n",
    "ti = grid_df[\"time_idx\"]\n",
    "assert grid_df.select(pl.col(\"time_idx\").is_duplicated().any()).item() is False\n",
    "assert ti.max() - ti.min() + 1 == len(ti), \"全局 time_idx 不连续\"\n",
    "\n",
    "# 3) 时间窗 + join time_idx + 选列\n",
    "lo = cfg[\"dates\"][\"tft_dates\"][\"date_lo\"]; hi = cfg[\"dates\"][\"tft_dates\"][\"date_hi\"]\n",
    "lw = lf.filter(pl.col(g_date).is_between(lo, hi, closed=\"both\"))\n",
    "lw_with_idx = (\n",
    "    lw.join(grid_lazy, on=[g_date, g_time], how=\"left\")\n",
    "        .select(need_cols + [\"time_idx\"])\n",
    "        .sort(TIME_SORT)\n",
    ")\n",
    "print(f\"[{_now()}][tft] schema -> {lw_with_idx.collect_schema().names()}\")\n",
    "\n",
    "# 4) 取一个窗口 demo → pandas（你可以换成全量）\n",
    "demo_lo, demo_hi = 1610, 1698\n",
    "df = (\n",
    "    lw_with_idx\n",
    "    .filter(pl.col(g_date).is_between(demo_lo, demo_hi, closed=\"both\"))\n",
    "    .collect(streaming=True)\n",
    "    .to_pandas()\n",
    ").sort_values([g_sym, \"time_idx\"])\n",
    "\n",
    "# 打印df实际日期范围\n",
    "print(f\"实际日期范围: {df[g_date].min()} 到 {df[g_date].max()}\")\n",
    "\n",
    "# 类型\n",
    "df[g_sym] = df[g_sym].astype(\"string\").astype(\"category\")\n",
    "df[\"time_idx\"] = df[\"time_idx\"].astype(\"int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_col].describe()  # 查看 target 分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[weight_col].describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c98c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f774a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  # 查看缺失情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失处理（只作用于连续特征，不动 target/weight）\n",
    "miss_flags, df = add_missing_flags_and_fill(df, g_sym, feature_cols)\n",
    "\n",
    "# 降精度\n",
    "for c in feature_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"float\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643306c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因果切分\n",
    "cutoff = int(df[\"time_idx\"].quantile(0.9))\n",
    "train_df = df[df[\"time_idx\"] <= cutoff].copy()\n",
    "val_df   = df[df[\"time_idx\"] >  cutoff].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb604fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"symbol_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import NaNLabelEncoder, GroupNormalizer\n",
    "\n",
    "# unknown_reals：特征 + 标记（不包含 weight）\n",
    "unknown_reals = list(dict.fromkeys(feature_cols + miss_flags))\n",
    "# TimeSeriesDataSet —— 把权重列作为 weight 传入；不要放进 unknown_reals； 按照group对自变量做标准化\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df.sort_values([g_sym, \"time_idx\"]),\n",
    "    time_idx=\"time_idx\",\n",
    "    target=target_col,\n",
    "    group_ids=[g_sym],\n",
    "    weight=weight_col,       # 关键：启用“样本加权”\n",
    "    \n",
    "    max_encoder_length=36,\n",
    "    max_prediction_length=1,\n",
    "    static_categoricals=[g_sym],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=unknown_reals,   # 不含 weight\n",
    "    \n",
    "    target_normalizer=None,\n",
    "    scalers={c: GroupNormalizer(groups=[g_sym]) for c in feature_cols},\n",
    "    \n",
    "    categorical_encoders={g_sym: NaNLabelEncoder(add_nan=True)},\n",
    "    add_relative_time_idx=True, add_target_scales=True, add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, val_df, stop_randomization=True)\n",
    "\n",
    "train_loader = training.to_dataloader(\n",
    "    train=True, batch_size=int(cfg.get(\"tft\",{}).get(\"batch_size\", 1024)), num_workers=4\n",
    ")\n",
    "val_loader = validation.to_dataloader(\n",
    "    train=False, batch_size=int(cfg.get(\"tft\",{}).get(\"batch_size\", 1024)), num_workers=4\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MAE  # 你这版有 MSE 就换 MSE()\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    loss=MAE(),\n",
    "    learning_rate=float(cfg.get(\"tft\", {}).get(\"lr\", 1e-3)),\n",
    "    hidden_size=int(cfg.get(\"tft\", {}).get(\"hidden_size\", 128)),\n",
    "    attention_head_size=int(cfg.get(\"tft\", {}).get(\"heads\", 4)),\n",
    "    dropout=float(cfg.get(\"tft\", {}).get(\"dropout\", 0.2)),\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import lightning as L\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=P(\"local\", \"tft/logs\"), name=\"tft\", default_hp_metric=False)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "    ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1, filename=\"tft-best-{epoch:02d}-{val_loss:.5f}\"),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "]\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=int(cfg.get(\"tft\", {}).get(\"max_epochs\", 2)),\n",
    "    accelerator=\"auto\",\n",
    "    precision=32,          # 稳定优先，跑顺了再试 bf16\n",
    "    gradient_clip_val=0.5,\n",
    "    log_every_n_steps=50,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=P(\"local\", \"tft/ckpts\"),\n",
    ")\n",
    "\n",
    "L.seed_everything(int(cfg.get(\"seed\", 42)), workers=True)\n",
    "trainer.fit(tft, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 覆盖整个 validation dataloader 的预测\n",
    "pred = tft.predict(val_loader, mode=\"prediction\")\n",
    "# pred 通常是 [N, max_prediction_length]；你现在 max_prediction_length=1\n",
    "import torch, numpy as np\n",
    "if isinstance(pred, torch.Tensor):\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "pred = np.asarray(pred)\n",
    "y_pred = pred.squeeze()  # 变成 [N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tft.predict(val_loader, mode=\"prediction\", return_index=True)\n",
    "y_pred = res.output\n",
    "if isinstance(y_pred, torch.Tensor):\n",
    "    y_pred = y_pred.detach().cpu()\n",
    "# 压成一维（max_prediction_length=1 的情况）\n",
    "\n",
    "y_pred = y_pred[:, -1]\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred = pd.DataFrame(y_pred, columns=[\"y_pred\"])\n",
    "\n",
    "y_pred_index = res.index\n",
    "# join 真实值 val_df.target\n",
    "\n",
    "y_actual = y_pred_index.merge(\n",
    "    val_df[[g_sym, \"time_idx\", target_col]],\n",
    "    on=[g_sym, \"time_idx\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "# 拼接真实值与预测值\n",
    "y_pred_actual = pd.concat([y_actual, y_pred], axis=1)\n",
    "\n",
    "# 画图展示\n",
    "y_pred_actual.plot(x=\"time_idx\", y=[target_col, \"y_pred\"], kind=\"line\", alpha=0.7)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
