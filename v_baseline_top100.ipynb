{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed813b1",
   "metadata": {},
   "source": [
    "# å¯¼å…¥åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2cac4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin_ml/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/base/_base_model.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-23 15:18:06] imports ok\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "\n",
    "# â”€â”€ æ ‡å‡†åº“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# â”€â”€ ç¬¬ä¸‰æ–¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import lightning as L\n",
    "import lightning.pytorch as lp\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline\n",
    "from pytorch_forecasting.metrics import MAE, RMSE, MAPE, SMAPE, QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_forecasting.data import TorchNormalizer, GroupNormalizer\n",
    "\n",
    "\n",
    "# ä½ çš„å·¥ç¨‹å·¥å…·\n",
    "from pipeline.io import cfg, P, fs, storage_options, ensure_dir_local, ensure_dir_az\n",
    "from pipeline.stream_input_local import ShardedBatchStream  \n",
    "from pipeline.wr2 import WR2\n",
    "\n",
    "# ---- æ€§èƒ½/å…¼å®¹å¼€å…³ï¼ˆä»…ä¸€æ¬¡ï¼‰----\n",
    "os.environ.setdefault(\"POLARS_MAX_THREADS\", str(max(1, os.cpu_count() // 2)))\n",
    "pl.enable_string_cache()\n",
    "cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "import time as _t\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "def _now() -> str:\n",
    "    return _t.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"[{_now()}] imports ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a03bfe",
   "metadata": {},
   "source": [
    "# å®šä¹‰å·¥å…·å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856ce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# æ»‘åŠ¨çª—åˆ’åˆ†\n",
    "def make_sliding_cv_by_days(all_days: np.ndarray, *, n_splits: int, gap_days: int, train_to_val: int):\n",
    "    all_days = np.asarray(all_days).ravel()\n",
    "    K, R, G = n_splits, train_to_val, gap_days\n",
    "    usable = len(all_days) - G\n",
    "    if usable <= 0 or K <= 0 or R <= 0:\n",
    "        return []\n",
    "    V_base, rem = divmod(usable, R + K)\n",
    "    if V_base <= 0:\n",
    "        return []\n",
    "    T = R * V_base\n",
    "    v_lens = [V_base + 1 if i < rem else V_base for i in range(K)]\n",
    "    folds, v_lo = [], T + G\n",
    "    for V_i in v_lens:\n",
    "        v_hi, tr_hi, tr_lo = v_lo + V_i, v_lo - G, v_lo - G - T\n",
    "        if tr_lo < 0 or v_hi > len(all_days):\n",
    "            break\n",
    "        folds.append((all_days[tr_lo:tr_hi], all_days[v_lo:v_hi]))\n",
    "        v_lo = v_hi\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a432b",
   "metadata": {},
   "source": [
    "# åˆå§‹åŒ–å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4040fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config] ready\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = (1000, 1600)  # ä»…ç”¨äºæœ¬æ¬¡å®éªŒ\n",
    "\n",
    "# è¯»å…¥ç­›é€‰çš„æ‰€æœ‰ç‰¹å¾åˆ—\n",
    "\n",
    "path = Path(\"/mnt/data/js/exp/v1/models/tune/selected_covariant_features.txt\")\n",
    "filted_cols = path.read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "selected_features = pd.read_csv(\"/mnt/data/js/exp/v1/models/tune/feature_importance__fixed__fixed__mm_full_train__features__fs__1400-1698__cv2-g7-r4__seed42__top1000__1760906660__range830-1698__range830-1698__cv2-g7-r4__1760912739.csv\")\n",
    "\n",
    "df_cov_cols = selected_features[selected_features['feature'].isin(filted_cols)].copy()\n",
    "\n",
    "# æˆ‘ä»¬è¿™é‡Œé‡æ–°å½’ä¸€åŒ–ä¸€ä¸‹\n",
    "df_cov_cols[\"mean_gain\"] = (df_cov_cols['mean_gain'] / df_cov_cols['mean_gain'].sum()).astype(np.float32)\n",
    "df_e_features = df_cov_cols.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ========== 1) åˆå§‹åŒ–é…ç½® ==========\n",
    "\n",
    "# æ‰€æœ‰åˆ—\n",
    "G_SYM, G_DATE, G_TIME = cfg[\"keys\"]          # e.g. (\"symbol_id\",\"date_id\",\"time_id\")\n",
    "TARGET_COL = cfg[\"target\"]                   # e.g. \"responder_6\"\n",
    "WEIGHT_COL = cfg[\"weight\"]                   # å…è®¸ä¸º None\n",
    "\n",
    "TIME_FEATURES = [\"time_bucket\", \"time_pos\", \"time_sin\", \"time_cos\"]\n",
    "\n",
    "COV_FEATURES = df_e_features['feature'].iloc[:200].tolist() # å¯èƒ½å«æœ‰ç»„å†…å¸¸æ•°åˆ—\n",
    "\n",
    "STATIC_FEATURES = [c for c in COV_FEATURES if c in [\"feature_09\", \"feature_10\", \"feature_11\"]]\n",
    "\n",
    "CS_RANK_FEATURES = [c for c in COV_FEATURES if c.endswith(\"__csrank\")]\n",
    "\n",
    "CS_R_Z_FEATURES = [c for c in COV_FEATURES if c.endswith(\"__cs_z\") or c.endswith(\"__rz\")]\n",
    "\n",
    "\n",
    "do_z_co_cols = [c for c in COV_FEATURES if c not in STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES]\n",
    "\n",
    "# è®­ç»ƒ & CV è¶…å‚\n",
    "N_SPLITS     = 2\n",
    "GAP_DAYS     = 7\n",
    "TRAIN_TO_VAL = 6\n",
    "ENC_LEN      = 256\n",
    "DEC_LEN      = 1\n",
    "PRED_LEN     = DEC_LEN\n",
    "BATCH_SIZE   = 64\n",
    "LR           = 1e-2\n",
    "HIDDEN       = 16\n",
    "HEADS        = 1\n",
    "DROPOUT      = 0.3\n",
    "MAX_EPOCHS   = 10\n",
    "GRADIENT_CLIP_VAL = 1.0\n",
    "\n",
    "# æ•°æ®è·¯å¾„\n",
    "PANEL_DIR_AZ   = P(\"az\", cfg[\"paths\"].get(\"panel_shards\", \"panel_shards\"))\n",
    "\n",
    "TFT_LOCAL_ROOT = P(\"local\", \"tft\"); ensure_dir_local(TFT_LOCAL_ROOT)\n",
    "\n",
    "LOCAL_CLEAN_DIR = f\"{TFT_LOCAL_ROOT}/clean\"; ensure_dir_local(LOCAL_CLEAN_DIR)\n",
    "CKPTS_DIR = Path(TFT_LOCAL_ROOT) / \"ckpts\"; ensure_dir_local(CKPTS_DIR.as_posix())\n",
    "LOGS_DIR  = Path(TFT_LOCAL_ROOT) / \"logs\";  ensure_dir_local(LOGS_DIR.as_posix())\n",
    "\n",
    "\n",
    "print(\"[config] ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46945dbf",
   "metadata": {},
   "source": [
    "# å¯¼å…¥æ•°æ®ï¼Œæ·»åŠ å…¨å±€time_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917caa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = fs.glob(\"az://jackson/js_exp/exp/v1/panel_shards/*.parquet\")\n",
    "data_paths =[f\"az://{p}\" for p in data_paths]\n",
    "\n",
    "lf_data = (\n",
    "    pl.scan_parquet(data_paths, storage_options=storage_options)\n",
    "    .select([*cfg['keys'], WEIGHT_COL, TARGET_COL, *TIME_FEATURES, *COV_FEATURES])\n",
    "    .filter(pl.col(G_DATE).is_between(start_date, end_date, closed=\"both\"))\n",
    ")\n",
    "lf_data = lf_data.sort([G_SYM, G_DATE, G_TIME])\n",
    "\n",
    "\n",
    "# å…ˆå½’ä¸€åŒ–time_pos\n",
    "lf_data = lf_data.with_columns(\n",
    "    (pl.col(\"time_pos\") / pl.lit(968)).cast(pl.Float32).alias(\"time_pos\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a74eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_data.limit(10).collect()  # è§¦å‘è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c37451",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = (\n",
    "    lf_data.select([G_DATE, G_TIME]).unique()\n",
    "        .sort([G_DATE, G_TIME])\n",
    "        .with_row_index(\"time_idx\")\n",
    "        .with_columns(pl.col(\"time_idx\").cast(pl.Int64))\n",
    "        .collect(streaming=True)\n",
    ")\n",
    "\n",
    "container_prefix = \"az://jackson/js_exp/exp/v1/tft/panel_clean_shards\"; ensure_dir_az(container_prefix)\n",
    "chunk_size = 30\n",
    "for lo in range(start_date, end_date + 1, chunk_size):\n",
    "    hi = min(lo + chunk_size - 1, end_date)\n",
    "    print(f\"processing date range: {lo} ~ {hi}\")\n",
    "    \n",
    "    lf_chunk = lf_data.filter(pl.col(G_DATE).is_between(lo, hi, closed=\"both\"))\n",
    "    \n",
    "    lf_grid_chunk = (\n",
    "        grid_df.lazy().filter(pl.col(G_DATE).is_between(lo, hi, closed=\"both\"))\n",
    "    )\n",
    "    \n",
    "    lf_joined = (\n",
    "        lf_chunk.join(lf_grid_chunk, on=[G_DATE, G_TIME], how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "    )\n",
    "    \n",
    "    out_path = f\"{container_prefix}/panel_clean_{lo:04d}_{hi:04d}.parquet\"\n",
    "    print(f\"writing to: {out_path}\")\n",
    "    \n",
    "    lf_joined.sink_parquet(\n",
    "        out_path,\n",
    "        storage_options=storage_options,\n",
    "        compression=\"zstd\",\n",
    "    )\n",
    "    \n",
    "del lf_data, lf_chunk, lf_grid_chunk, lf_joined; gc.collect()\n",
    "print(f\"[{_now()}] all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6633f",
   "metadata": {},
   "source": [
    "# é‡æ–°å¯¼å…¥å«æœ‰time_idxçš„æ•°æ® & CV åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daec9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_prefix = \"az://jackson/js_exp/exp/v1/tft/panel_clean_shards\"\n",
    "data_paths = fs.glob(f\"{container_prefix}/*.parquet\")\n",
    "data_paths = [f\"az://{p}\" for p in data_paths] \n",
    "lf_with_idx = pl.scan_parquet(data_paths, storage_options=storage_options).filter(pl.col(G_DATE).is_between(start_date, end_date, closed=\"both\")).sort([G_SYM, \"time_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63da710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cv] total 2 folds\n",
      "[(array([1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010,\n",
      "       1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021,\n",
      "       1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032,\n",
      "       1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043,\n",
      "       1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054,\n",
      "       1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065,\n",
      "       1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076,\n",
      "       1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087,\n",
      "       1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098,\n",
      "       1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109,\n",
      "       1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120,\n",
      "       1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131,\n",
      "       1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142,\n",
      "       1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153,\n",
      "       1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164,\n",
      "       1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,\n",
      "       1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186,\n",
      "       1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197,\n",
      "       1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208,\n",
      "       1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219,\n",
      "       1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230,\n",
      "       1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241,\n",
      "       1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252,\n",
      "       1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263,\n",
      "       1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274,\n",
      "       1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285,\n",
      "       1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296,\n",
      "       1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307,\n",
      "       1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318,\n",
      "       1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329,\n",
      "       1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340,\n",
      "       1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351,\n",
      "       1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362,\n",
      "       1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373,\n",
      "       1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384,\n",
      "       1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395,\n",
      "       1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406,\n",
      "       1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417,\n",
      "       1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428,\n",
      "       1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439,\n",
      "       1440, 1441, 1442, 1443], dtype=int32), array([1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461,\n",
      "       1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472,\n",
      "       1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483,\n",
      "       1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494,\n",
      "       1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505,\n",
      "       1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516,\n",
      "       1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525], dtype=int32)), (array([1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085,\n",
      "       1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096,\n",
      "       1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107,\n",
      "       1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118,\n",
      "       1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129,\n",
      "       1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140,\n",
      "       1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151,\n",
      "       1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162,\n",
      "       1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173,\n",
      "       1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184,\n",
      "       1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195,\n",
      "       1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206,\n",
      "       1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217,\n",
      "       1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228,\n",
      "       1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239,\n",
      "       1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250,\n",
      "       1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261,\n",
      "       1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272,\n",
      "       1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283,\n",
      "       1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294,\n",
      "       1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305,\n",
      "       1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316,\n",
      "       1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327,\n",
      "       1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338,\n",
      "       1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349,\n",
      "       1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360,\n",
      "       1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371,\n",
      "       1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382,\n",
      "       1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393,\n",
      "       1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404,\n",
      "       1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415,\n",
      "       1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426,\n",
      "       1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437,\n",
      "       1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448,\n",
      "       1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459,\n",
      "       1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470,\n",
      "       1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481,\n",
      "       1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492,\n",
      "       1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503,\n",
      "       1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514,\n",
      "       1515, 1516, 1517, 1518], dtype=int32), array([1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536,\n",
      "       1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547,\n",
      "       1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558,\n",
      "       1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569,\n",
      "       1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580,\n",
      "       1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591,\n",
      "       1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "# ==========  CV åˆ’åˆ† ==========\n",
    "all_days = (\n",
    "    lf_with_idx.select(pl.col(G_DATE)).unique().sort([G_DATE])\n",
    "    .collect(streaming=True)[G_DATE].to_numpy()\n",
    ")\n",
    "folds_by_day = make_sliding_cv_by_days(all_days, n_splits=N_SPLITS, gap_days=GAP_DAYS, train_to_val=TRAIN_TO_VAL)\n",
    "\n",
    "print(f\"[cv] total {len(folds_by_day)} folds\")\n",
    "\n",
    "assert len(folds_by_day) > 0, \"no CV folds constructed\"\n",
    "print(folds_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff439b97",
   "metadata": {},
   "source": [
    "# æ¥ä¸‹æ¥å‡å·²ç¬¬ä¸€æŠ˜ä¸ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e614fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»Ÿè®¡æ ‡å‡†åŒ–ä½¿ç”¨è®­ç»ƒé›†çš„æ—¥æœŸèŒƒå›´ = 1000 ~ 1443\n",
      "éªŒè¯é›†æ—¥æœŸèŒƒå›´ = 1451 ~ 1525\n"
     ]
    }
   ],
   "source": [
    "fold_id = 0\n",
    "# å–ç¬¬ä¸€ä¸ª fold çš„è®­ç»ƒé›†æœ€åä¸€å¤©ï¼Œä½œä¸ºæœ¬æŠ˜ç»Ÿè®¡ z-score çš„ä¸Šç•Œ\n",
    "train_lo, train_hi = folds_by_day[fold_id][0][0], folds_by_day[fold_id][0][-1]\n",
    "val_lo, val_hi = folds_by_day[fold_id][1][0], folds_by_day[fold_id][1][-1]\n",
    "\n",
    "print(f\"ç»Ÿè®¡æ ‡å‡†åŒ–ä½¿ç”¨è®­ç»ƒé›†çš„æ—¥æœŸèŒƒå›´ = {train_lo} ~ {train_hi}\")\n",
    "print(f\"éªŒè¯é›†æ—¥æœŸèŒƒå›´ = {val_lo} ~ {val_hi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0689de",
   "metadata": {},
   "source": [
    "# æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d547d97",
   "metadata": {},
   "source": [
    "## å¡«è¡¥å› ä¸ºç‰¹å¾å·¥ç¨‹äº§ç”Ÿçš„ç¼ºå¤±åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—è®­ç»ƒé›†çš„å„ç‰¹å¾é‡çš„ä¸­ä½æ•°\n",
    "lf_tr = lf_with_idx.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "\n",
    "grp_median = (\n",
    "    lf_tr\n",
    "    .group_by([G_SYM, \"time_pos\"])\n",
    "    .agg([\n",
    "        pl.col(col).median().alias(f\"{col}_median_st\") for col in COV_FEATURES\n",
    "    ])\n",
    "    .sort([G_SYM, \"time_pos\"])\n",
    ")\n",
    "\n",
    "glb_median = (\n",
    "    lf_tr\n",
    "    .group_by(\"time_pos\")\n",
    "    .agg([\n",
    "        pl.col(col).median().alias(f\"{col}_median_t\") for col in COV_FEATURES\n",
    "    ])\n",
    "    .sort(\"time_pos\")\n",
    ")\n",
    "\n",
    "# åº”ç”¨äºæœ¬æŠ˜å…¨éƒ¨æ•°æ® trian + val\n",
    "lf_all = lf_with_idx.join(grp_median, on=[G_SYM, \"time_pos\"], how=\"left\").join(glb_median, on=[\"time_pos\"], how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "# é€åˆ—ç”¨ä¸­ä½æ•°æ›¿æ¢ç¼ºå¤±å€¼\n",
    "fill_exprs = []\n",
    "\n",
    "for col in COV_FEATURES:\n",
    "    fill_exprs.append(\n",
    "        pl.coalesce([\n",
    "            pl.col(col),\n",
    "            pl.col(f\"{col}_median_st\"),\n",
    "            pl.col(f\"{col}_median_t\")\n",
    "        ]).alias(col)\n",
    "    )\n",
    "\n",
    "lf_all_imputed = lf_all.with_columns(fill_exprs)\n",
    "\n",
    "# å»æ‰ä¸­ä½æ•°åˆ—\n",
    "drop_cols = [f\"{col}_median_st\" for col in COV_FEATURES]\n",
    "drop_cols += [f\"{col}_median_t\" for col in COV_FEATURES]\n",
    "lf_all_imputed = lf_all_imputed.drop(drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f75c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "    df_null_lf_all_imputed = lf_all_imputed.select(\n",
    "        pl.all().null_count()\n",
    "    ).collect().to_pandas().T.sort_values(by=0, ascending=False)\n",
    "\n",
    "    assert df_null_lf_all_imputed.iloc[0,0] == 0, \"ä»æœ‰ç¼ºå¤±å€¼æœªå¡«è¡¥å®Œæˆï¼\"\n",
    "\n",
    "    del lf_tr, grp_median, glb_median, lf_all, df_null_lf_all_imputed; gc.collect()\n",
    "\n",
    "del lf_tr, grp_median, glb_median, lf_all; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89886d48",
   "metadata": {},
   "source": [
    "## é™æ€ç‰¹å¾å½’ä¸€åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a20f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_tr_imputed = lf_all_imputed.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "\n",
    "static_glb_minmax = (\n",
    "    lf_tr_imputed.select(\n",
    "        *[pl.col(c).min().alias(f\"{c}_min\") for c in STATIC_FEATURES],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max\") for c in STATIC_FEATURES],\n",
    "    ).collect().to_dicts()[0]   # â† ç”¨ to_dicts()[0]\n",
    ")\n",
    "\n",
    "eps = 1e-8\n",
    "\n",
    "lf_all = lf_all_imputed.with_columns([\n",
    "    (\n",
    "        ((pl.col(c) - pl.lit(static_glb_minmax[f\"{c}_min\"])) /\n",
    "         (pl.lit(static_glb_minmax[f\"{c}_max\"] - static_glb_minmax[f\"{c}_min\"]) + eps))\n",
    "        .clip(0.0, 1.0)\n",
    "    ).cast(pl.Float32).alias(c)   # â† cast/alias ä½œç”¨äºâ€œæ•´ä¸ªç»“æœâ€\n",
    "    for c in STATIC_FEATURES\n",
    "])\n",
    "\n",
    "# ä¸éœ€è¦ dropï¼ˆä½ æ²¡åˆ›å»º *_glb_min/_glb_max åˆ—ï¼‰\n",
    "del lf_tr_imputed, static_glb_minmax; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b2784",
   "metadata": {},
   "source": [
    "## æ ‡å‡†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Z-score ==========\n",
    "# è®¡ç®— è®­ç»ƒé›† stats\n",
    "\n",
    "lf_tr = lf_all.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "grp_stats = (\n",
    "    lf_tr\n",
    "    .group_by(G_SYM)\n",
    "    .agg([pl.col(c).mean().alias(f\"mu_grp_{c}\") for c in do_z_co_cols] +\n",
    "        [pl.col(c).std().alias(f\"std_grp_{c}\") for c in do_z_co_cols])\n",
    ").collect(streaming=True)\n",
    "\n",
    "glb_stats = (\n",
    "    lf_tr\n",
    "    .select([pl.col(c).mean().alias(f\"mu_glb_{c}\") for c in do_z_co_cols] +\n",
    "            [pl.col(c).std().alias(f\"std_glb_{c}\") for c in do_z_co_cols])\n",
    ").collect(streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb73a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "glb_row = glb_stats.to_dicts()[0]\n",
    "\n",
    "# é€æ—¥æ ‡å‡†åŒ–æœ¬æŠ˜æ‰€æœ‰æ•°æ®å¹¶ä¿å­˜\n",
    "fold_root = f\"az://jackson/js_exp/exp/v1/tft/fold_{fold_id}\"; ensure_dir_az(fold_root)\n",
    "z_prefix = f\"{fold_root}/z_shards\"; ensure_dir_az(z_prefix)\n",
    "\n",
    "z_done_cols = [f\"z_{c}\" for c in (do_z_co_cols)]\n",
    "min_std = 1e-5\n",
    "eps = 1e-8\n",
    "\n",
    "# é¢„å¤„ç†å…¨å±€å‡å€¼/æ–¹å·®çš„å…œåº•ï¼Œé¿å…åœ¨è¡Œçº§åˆ¤æ–­\n",
    "glb_mu = {c: glb_row[f\"mu_glb_{c}\"] for c in do_z_co_cols}\n",
    "glb_std = {}\n",
    "for c in do_z_co_cols:\n",
    "    s = glb_row[f\"std_glb_{c}\"]\n",
    "    if s is None or s <= 0:\n",
    "        s = min_std\n",
    "    glb_std[c] = s\n",
    "\n",
    "for d in range(train_lo, val_hi + 1):\n",
    "    lf_day = lf_all.filter(pl.col(G_DATE) == d)\n",
    "\n",
    "    lf_day_z = lf_day.join(grp_stats.lazy(), on=G_SYM, how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "    # 1) å…ˆæŠŠæ‰€æœ‰â€œå¸¸é‡â€å˜æˆå…·ååˆ—ï¼Œé¿å… anonymous literal\n",
    "    const_exprs = []\n",
    "    for c in do_z_co_cols:\n",
    "        const_exprs += [\n",
    "            pl.lit(glb_mu[c]).alias(f\"__mu_glb_{c}\"),\n",
    "            pl.lit(glb_std[c] if glb_std[c] > 0 else min_std).alias(f\"__std_glb_{c}\"),\n",
    "        ]\n",
    "    lf_day_z = lf_day_z.with_columns(const_exprs)\n",
    "\n",
    "    # 2) è®¡ç®— zï¼Œå¹¶ç”¨ clip è£å‰ª\n",
    "    exprs = []\n",
    "    for c in do_z_co_cols:\n",
    "        mu_grp  = pl.col(f\"mu_grp_{c}\")\n",
    "        std_grp = pl.col(f\"std_grp_{c}\")\n",
    "        mu_use = pl.coalesce([mu_grp, pl.col(f\"__mu_glb_{c}\")]).cast(pl.Float32)\n",
    "\n",
    "        std_tmp = pl.when(std_grp.is_null() | (std_grp <= 0))\\\n",
    "                    .then(pl.col(f\"__std_glb_{c}\"))\\\n",
    "                    .otherwise(std_grp)\n",
    "        std_use = pl.when(std_tmp < min_std).then(min_std).otherwise(std_tmp).cast(pl.Float32)\n",
    "\n",
    "        z = ((pl.col(c).cast(pl.Float32) - mu_use) / (std_use + eps)).clip(-3.0, 3.0).alias(f\"z_{c}\")\n",
    "        exprs.append(z)\n",
    "\n",
    "    lf_day_z = lf_day_z.with_columns(exprs)\n",
    "    \n",
    "    keep = [\n",
    "        \"time_idx\", G_SYM, G_DATE, G_TIME, WEIGHT_COL, TARGET_COL\n",
    "    ] + TIME_FEATURES + STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES + z_done_cols\n",
    "        \n",
    "\n",
    "    # å»é‡ä½†ä¿æŒé¡ºåºï¼ˆé¿å… DuplicateErrorï¼‰\n",
    "    keep = list(dict.fromkeys(keep))\n",
    "    \n",
    "    lf_out = lf_day_z.select(keep).sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "    out_path = f\"{z_prefix}/z_{d:04d}.parquet\"\n",
    "    lf_out.collect(streaming=True).write_parquet(\n",
    "        out_path, storage_options=storage_options, compression=\"zstd\"\n",
    "    )\n",
    "    print(f\"wrote z-scored data for day {d} to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ee42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lf_tr, grp_stats, glb_stats; gc.collect()\n",
    "del lf_day_z, lf_all; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b3677",
   "metadata": {},
   "source": [
    "# æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd251d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight col: weight\n",
      "target cols: responder_6\n",
      "encode length: 256, pred length: 1\n",
      "input varying_reals_cols: ['time_pos', 'time_sin', 'time_cos', 'feature_09', 'feature_11', 'feature_60__csrank', 'feature_26__csrank', 'feature_60__cs_z', 'feature_59__cs_z', 'z_feature_06', 'z_feature_36', 'z_feature_04', 'z_feature_59__rstd30', 'z_feature_07', 'z_feature_61__ret50', 'z_feature_31__lag4840', 'z_feature_61__lag7744', 'z_feature_61__diff50', 'z_feature_51__ewm10', 'z_feature_61__lag1936', 'z_feature_59__ewm5', 'z_feature_48', 'z_feature_61__lag900', 'z_feature_59', 'z_feature_51__rmean14', 'z_feature_31__diff50', 'z_feature_04__ewm5', 'z_feature_61__lag3872', 'z_feature_04__ewm10', 'z_feature_06__rz30', 'z_feature_60__rstd30', 'z_feature_54__ewm10', 'z_feature_37__rstd30', 'z_feature_22__diff50', 'z_feature_30__lag50', 'z_feature_01__ewm50', 'z_feature_61__lag4840', 'z_feature_61__lag2904', 'z_responder_2_prev_tail_lag10', 'z_feature_26__lag900', 'z_feature_08__ewm50', 'z_feature_20__diff50', 'z_feature_04__ewm50', 'z_responder_5_prevday_mean', 'z_feature_31__lag1936', 'z_feature_75__rstd7', 'z_feature_58__ewm50', 'z_feature_43__ewm50', 'z_feature_25__diff50', 'z_feature_30__lag968', 'z_feature_40__ewm10', 'z_responder_7_close_roll14_std', 'z_responder_8_prevday_mean', 'z_feature_61__lag6776', 'z_responder_7_prev_tail_lag967', 'z_responder_6_prevday_std', 'z_feature_38__lag100', 'z_feature_26__diff50', 'z_feature_76__rstd14', 'z_feature_55__ewm50', 'z_feature_52__rstd30', 'z_feature_61__lag5808', 'z_responder_3_prevday_std', 'z_feature_26__lag6776', 'z_feature_06__ewm10', 'z_responder_8_prev_tail_lag967', 'z_feature_07__rmean3', 'z_feature_75__rstd3', 'z_feature_08__rmean30', 'z_feature_08__lag100', 'z_feature_30__diff50', 'z_feature_25__ret50', 'z_feature_42__rmean30', 'z_feature_21__diff50', 'z_feature_59__ewm50', 'z_responder_6_prev_tail_lag967', 'z_feature_07__rmean30', 'z_feature_24__lag4840', 'z_feature_38__ewm50', 'z_feature_68__ewm10', 'z_feature_30__lag3872', 'z_feature_05__rstd30', 'z_feature_42__ewm50', 'z_feature_45__ewm5', 'z_feature_24__diff50', 'z_feature_31__ret50', 'z_feature_05__rmean30', 'z_feature_23__diff50', 'z_responder_6_prev_tail_lag50', 'z_feature_59__rstd14', 'z_feature_21__lag900', 'z_feature_06__rmean14', 'z_feature_21__ret50', 'z_feature_54__rmean14', 'z_feature_05__ewm50', 'z_feature_23__ret50', 'z_feature_58', 'z_feature_53__ewm50', 'z_feature_24', 'z_feature_47__rstd30', 'z_feature_33__rmean3', 'z_feature_61__lag500', 'z_feature_27__ret50', 'z_feature_51__ewm50', 'z_feature_38__rstd30', 'z_responder_6_prevday_mean', 'z_feature_07__rmean14', 'z_feature_28__ret50', 'z_feature_48__rstd30', 'z_feature_34__diff50', 'z_feature_51__ewm5', 'z_responder_2_prevday_std', 'z_responder_7_prev_tail_lag500', 'z_feature_60', 'z_feature_16__ewm5', 'z_feature_15__rstd30', 'z_feature_56', 'z_responder_8_prevday_std', 'z_responder_3_prev_tail_lag100', 'z_responder_3_prev_tail_lag967', 'z_feature_44__ewm50', 'z_feature_23__lag100', 'z_responder_6_prev_tail_lag900', 'z_feature_24__lag1936', 'z_feature_58__rmean3', 'z_feature_15__ewm50', 'z_feature_26__ret50', 'z_feature_30__lag900', 'z_responder_4_prev_tail_lag967', 'z_feature_60__ewm50', 'z_feature_27__diff50', 'z_feature_38', 'z_feature_04__rstd30', 'z_responder_0_close_roll14_std', 'z_responder_1_close_roll30_std', 'z_feature_47__ewm50', 'z_feature_54__ewm50', 'z_feature_22__lag2904', 'z_feature_68__ewm50', 'z_feature_20__ret50', 'z_feature_47', 'z_feature_30__lag1936', 'z_feature_24__ret50', 'z_feature_29__diff50', 'z_responder_7_prevday_std', 'z_feature_28__diff50', 'z_responder_0_prev_tail_lag10', 'z_feature_20__lag950', 'z_feature_59__rstd3', 'z_responder_3_close_roll7_std', 'z_feature_56__ewm5', 'z_responder_7_prev_tail_lag950', 'z_feature_61__lag1', 'z_feature_66__rstd30', 'z_feature_66__ewm10', 'z_feature_45__ewm10', 'z_feature_23__lag4840', 'z_responder_2_close_roll7_std', 'z_responder_0_prev_tail_lag900', 'z_feature_26__lag4840', 'z_feature_07__ewm5', 'z_responder_1_prevday_std', 'z_responder_0_prevday_std', 'z_responder_2_close_roll14_mean', 'z_responder_6_close_roll14_std', 'z_responder_0_close_roll30_std', 'z_responder_3_prevday_mean', 'z_responder_8_prev_tail_lag950', 'z_feature_04__rmean3', 'z_feature_06__ewm50', 'z_feature_26__lag950', 'z_responder_1_close_roll3_std', 'z_feature_13__ewm5', 'z_feature_33__rmean7', 'z_responder_4_prevday_std', 'z_feature_08__lag500', 'z_feature_30__ret50', 'z_feature_22__lag1', 'z_feature_75__rstd14', 'z_responder_7_prev_tail_lag100', 'z_feature_38__lag500', 'z_responder_1_close_roll14_std', 'z_feature_19__ewm10', 'z_feature_49__ewm50', 'z_responder_5_prev_tail_lag10', 'z_feature_59__rstd7', 'z_feature_55__rmean14', 'z_responder_0_close_roll3_std', 'z_feature_68__rmean14', 'z_responder_3_prev_tail_lag950', 'z_feature_22__lag6776', 'z_feature_22__lag4840', 'z_feature_26__lag1936', 'z_feature_01__rmean30', 'z_feature_22__lag1936', 'z_feature_07__ewm50', 'z_feature_24__lag900', 'z_feature_33__ewm50', 'z_responder_8_prev_tail_lag500', 'z_feature_39__ewm50', 'z_feature_36__ewm5', 'z_feature_02__rmean30', 'z_feature_61__lag950']\n",
      "input varying_categorical_cols: ['time_bucket', 'gap_flag']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7426"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.seed_everything(42) \n",
    "\n",
    "z_done_cols = [f\"z_{c}\" for c in do_z_co_cols]\n",
    "\n",
    "# æ˜ç¡®è¾“å…¥çš„å„åˆ—\n",
    "known_varying_categorical_cols = [\"time_bucket\", \"gap_flag\"] # gap_flag éœ€è¦åç»­æ·»åŠ \n",
    "\n",
    "known_varying_reals_cols = [\"time_pos\", \"time_sin\", \"time_cos\"] + STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES + z_done_cols\n",
    "unscaler_cols = known_varying_reals_cols\n",
    "\n",
    "TRAIN_COLS = [G_SYM, G_DATE, G_TIME, \"time_idx\", WEIGHT_COL, TARGET_COL] + known_varying_categorical_cols + known_varying_reals_cols \n",
    "\n",
    "print(f\"weight col: {WEIGHT_COL}\")\n",
    "print(f\"target cols: {TARGET_COL}\")\n",
    "print(f\"encode length: {ENC_LEN}, pred length: {PRED_LEN}\")\n",
    "print(f\"input varying_reals_cols: {known_varying_reals_cols}\")\n",
    "print(f\"input varying_categorical_cols: {known_varying_categorical_cols}\")\n",
    "\n",
    "\n",
    "# å¯¼å…¥ æœ¬æŠ˜z-score åçš„æ•°æ®è¿›è¡Œåç»­å¤„ç†\n",
    "fold_root = f\"az://jackson/js_exp/exp/v1/tft/fold_{fold_id}\"\n",
    "z_prefix = f\"{fold_root}/z_shards\"\n",
    "\n",
    "data_paths = fs.glob(f\"{z_prefix}/*.parquet\")\n",
    "data_paths = [f\"az://{p}\" for p in data_paths]\n",
    "lf = pl.scan_parquet(data_paths, storage_options=storage_options).sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "# æ·»åŠ  gap_flag åˆ—\n",
    "# åªä¿ç•™ symbolÃ—date å”¯ä¸€ç»„åˆå¹¶æ’åº\n",
    "lf_grp_date = (\n",
    "    lf.select([pl.col(G_SYM), pl.col(G_DATE)])\n",
    "      .unique()\n",
    "      .sort([G_SYM, G_DATE])\n",
    ")\n",
    "\n",
    "lf_gap = lf_grp_date.with_columns(\n",
    "    pl.col(G_DATE).diff().over(G_SYM).fill_null(1).alias(\"date_diff\")\n",
    ").with_columns(\n",
    "    (pl.col(\"date_diff\") > 1).cast(pl.Int8).alias(\"gap_flag\")\n",
    ").select(\n",
    "    G_SYM, G_DATE, \"gap_flag\"\n",
    ").sort([G_SYM, G_DATE])\n",
    "\n",
    "\n",
    "lf = lf.join(lf_gap, on=[G_SYM, G_DATE], how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "del lf_grp_date, lf_gap; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04668e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…ˆåªå–ä¸€ä¸ªsymbolè®­ç»ƒ\n",
    "\n",
    "lf = lf.select(TRAIN_COLS)\n",
    "lf = lf.filter(pl.col(G_SYM) == 0)\n",
    "\n",
    "df = lf.collect(streaming=True).to_pandas()\n",
    "\n",
    "\n",
    "df[G_SYM] = df[G_SYM].astype(str).astype(\"category\")\n",
    "\n",
    "# ç¡®ä¿ pandas dtypes\n",
    "df[\"time_bucket\"] = df[\"time_bucket\"].astype(str).astype(\"category\")\n",
    "df[\"gap_flag\"] = df[\"gap_flag\"].astype(str).astype(\"category\")\n",
    "\n",
    "for c in known_varying_reals_cols:\n",
    "    df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    \n",
    "df[TARGET_COL] = df[TARGET_COL].astype(np.float32)\n",
    "df[WEIGHT_COL] = df[WEIGHT_COL].astype(np.float32)\n",
    "\n",
    "df.sort_values(by=[G_SYM, \"time_idx\"], inplace=True)\n",
    "\n",
    "\n",
    "train_start_idx = df[df[G_DATE] == train_lo][\"time_idx\"].min()\n",
    "train_end_idx   = df[df[G_DATE] == train_hi][\"time_idx\"].max()\n",
    "val_start_idx   = df[df[G_DATE] == val_lo][\"time_idx\"].min()\n",
    "val_end_idx     = df[df[G_DATE] == val_hi][\"time_idx\"].max()\n",
    "\n",
    "df_train = df.loc[df.time_idx.between(train_start_idx, train_end_idx)].copy()\n",
    "\n",
    "warmup_len = ENC_LEN\n",
    "df_val_ctx   = df.loc[df.time_idx.between(val_start_idx-warmup_len, val_end_idx)].copy()\n",
    "\n",
    "df_train[\"time_idx\"] = df_train[\"time_idx\"].astype(\"int64\")\n",
    "df_val_ctx[\"time_idx\"]   = df_val_ctx[\"time_idx\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15297c",
   "metadata": {},
   "source": [
    "## æ ¸æŸ¥æ•°æ®æ˜¯å¦é€‚åˆè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"æ€»è¡Œæ•°:\", len(df))\n",
    "print(\"è®­ç»ƒ/éªŒè¯è¡Œæ•°:\", len(df_train), len(df_val_ctx))\n",
    "print(\"åˆ†ç»„æ•°:\", df[G_SYM].nunique())\n",
    "print(\"è®­ç»ƒé›†åˆ†ç»„æ•°:\", df_train[G_SYM].nunique())\n",
    "print(\"éªŒè¯é›†åˆ†ç»„æ•°:\", df_val_ctx[G_SYM].nunique())\n",
    "print(\"æ—¥æœŸèŒƒå›´:\", df[G_DATE].min(), \"â†’\", df[G_DATE].max())\n",
    "\n",
    "# å…³é”®é”®æ˜¯å¦å”¯ä¸€ï¼ˆé˜²é‡å¤ï¼‰\n",
    "dup_keys = df.duplicated(subset=[G_SYM, \"time_idx\"], keep=False).sum()\n",
    "print(\"é‡å¤ (sym, time_idx) è¡Œæ•°:\", dup_keys)\n",
    "assert dup_keys == 0, \"å‘ç° (sym, time_idx) é‡å¤ï¼Œè¯·å…ˆå»é‡ï¼\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›®æ ‡/æƒé‡åˆæ³•æ€§\n",
    "print(\"ç›®æ ‡ç¼ºå¤±/éæœ‰é™:\", (~np.isfinite(df[TARGET_COL])).sum())\n",
    "print(\"æƒé‡ç¼ºå¤±/éæœ‰é™:\", (~np.isfinite(df[WEIGHT_COL])).sum())\n",
    "print(\"æƒé‡è´Ÿå€¼è¡Œæ•°:\", (df[WEIGHT_COL] < 0).sum())\n",
    "\n",
    "# ç‰¹å¾ç¼ºå¤±\n",
    "na_counts = df[known_varying_reals_cols].isna().sum().sort_values(ascending=False)\n",
    "print(\"Top-10 ç‰¹å¾ç¼ºå¤±ï¼š\")\n",
    "print(na_counts.head(10))\n",
    "\n",
    "# å¸¸æ•°åˆ—ï¼ˆæ— æ–¹å·®ï¼Œå–‚æ¨¡å‹æ²¡æ„ä¹‰ï¼‰\n",
    "const_cols = []\n",
    "for c in known_varying_reals_cols:\n",
    "    s = df[c]\n",
    "    if s.notna().any() and np.nanstd(s.values.astype(np.float32)) == 0.0:\n",
    "        const_cols.append(c)\n",
    "print(\"å¸¸æ•°åˆ—æ•°é‡:\", len(const_cols), \"ç¤ºä¾‹:\", const_cols[:10])\n",
    "\n",
    "# æç«¯å€¼ï¼ˆQ0.1%~99.9%ä¹‹å¤–çš„å æ¯”ï¼‰\n",
    "def extreme_ratio(s):\n",
    "    ql, qh = np.nanpercentile(s.values, [0.1, 99.9])\n",
    "    return float(((s < ql) | (s > qh)).mean())\n",
    "extreme_report = {c: extreme_ratio(df[c]) for c in known_varying_reals_cols[:50]}  # å…ˆæŠ½50åˆ—çœ‹\n",
    "print(\"æç«¯å€¼å æ¯”ï¼ˆå‰50åˆ—ç¤ºä¾‹ï¼‰:\", sorted(extreme_report.items(), key=lambda x: -x[1])[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯ä¸ª symbol çš„ gap æ¯”ä¾‹ & æœ€å¤§è¿ç»­ç¼ºå£\n",
    "def gap_stats(g):\n",
    "    gaps = g[\"gap_flag\"].astype(bool).to_numpy()\n",
    "    gap_ratio = gaps.mean()\n",
    "    # ä¼°ç®—æœ€å¤§è¿ç»­ gap æ®µé•¿åº¦\n",
    "    # è‹¥ time_idx è¿ç»­é€’å¢ï¼Œè¿ç»­æ®µå¯ç”¨ diff>1 çš„ run-length æ¥è¿‘ä¼¼\n",
    "    d = g[\"time_idx\"].diff().fillna(1).to_numpy()\n",
    "    max_gap = int(d[d>1].max()) if (d>1).any() else 1\n",
    "    return pd.Series({\"gap_ratio\": gap_ratio, \"max_gap\": max_gap})\n",
    "\n",
    "gs = df.groupby(G_SYM, observed=True).apply(gap_stats)\n",
    "print(gs.describe())\n",
    "\n",
    "# éªŒè¯é›†é¦–ä¸ª time_idx æ˜¯å¦æœ‰è¶³å¤Ÿ warmup\n",
    "first_val = df_val_ctx.groupby(G_SYM, observed=True)[\"time_idx\"].min()\n",
    "need_warmup = (first_val < (val_start_idx - ENC_LEN)).sum()\n",
    "print(\"æœ‰ warmup çš„åˆ†ç»„æ•°:\", (first_val <= val_start_idx).sum(), \"ä¸è¶³ warmup çš„åˆ†ç»„æ•°:\", need_warmup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_end_idx < val_start_idx, \"è®­ç»ƒ/éªŒè¯æ—¶é—´æœ‰é‡å æˆ–å€’åºï¼Œè¯·æ£€æŸ¥ train_hi/val_loï¼\"\n",
    "\n",
    "# å„åˆ†ç»„åœ¨è®­ç»ƒ/éªŒè¯çš„è¦†ç›–æƒ…å†µ\n",
    "cov = pd.DataFrame({\n",
    "    \"train_rows\": df_train.groupby(G_SYM, observed=True).size(),\n",
    "    \"val_rows\":   df_val_ctx.groupby(G_SYM, observed=True).size(),\n",
    "}).fillna(0).astype(int)\n",
    "print(\"è®­ç»ƒ/éªŒè¯è¦†ç›–ï¼ˆå‰10ï¼‰ï¼š\")\n",
    "print(cov.head(10))\n",
    "bad_groups = cov.query(\"train_rows < @ENC_LEN or val_rows < 1\").index.tolist()\n",
    "print(\"æ½œåœ¨ä¸å¯è®­ç»ƒåˆ†ç»„æ•°:\", len(bad_groups), \"ç¤ºä¾‹:\", bad_groups[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ç›®æ ‡åˆ†å¸ƒ:\", df[TARGET_COL].describe(percentiles=[.01,.1,.5,.9,.99]))\n",
    "print(\"æƒé‡åˆ†å¸ƒ:\", df[WEIGHT_COL].describe(percentiles=[.01,.1,.5,.9,.99]))\n",
    "\n",
    "# æƒé‡ä¸º0çš„æ¯”ä¾‹ï¼ˆæœ‰çš„èµ›é¢˜æƒé‡0è¡¨ç¤ºå¿½ç•¥ï¼Œéœ€æ˜ç¡®ï¼‰\n",
    "w0_ratio = (df[WEIGHT_COL] == 0).mean()\n",
    "print(\"æƒé‡=0 å æ¯”:\", round(float(w0_ratio), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–æœ€è¿‘ä¸€æ®µçš„æŠ½æ ·ï¼Œé¿å…å¤§è¡¨è¿‡æ…¢\n",
    "sample = df.sample(min(500_000, len(df)), random_state=42)\n",
    "\n",
    "# ç®€æ˜“çš®å°”é€Šç›¸å…³ï¼ˆæ³¨æ„ï¼šæ—¶åºç›¸å…³ä¸ç­‰äºå¯ç”¨æ€§ï¼Œè¿™åªæ˜¯çº¢/ç»¿ç¯ï¼‰\n",
    "corrs = sample[known_varying_reals_cols + [TARGET_COL]].corr(numeric_only=True)[TARGET_COL].sort_values(ascending=False)\n",
    "print(\"ä¸ç›®æ ‡æœ€ç›¸å…³ Top-15ï¼š\")\n",
    "print(corrs.head(15))\n",
    "print(\"ä¸ç›®æ ‡æœ€è´Ÿç›¸å…³ Top-15ï¼š\")\n",
    "print(corrs.tail(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b806bd",
   "metadata": {},
   "source": [
    "## å‡†å¤‡è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9757ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=TARGET_COL,\n",
    "    group_ids=[G_SYM],\n",
    "    weight=WEIGHT_COL,\n",
    "    min_encoder_length=ENC_LEN,\n",
    "    max_encoder_length=ENC_LEN,\n",
    "    min_prediction_length=PRED_LEN,\n",
    "    max_prediction_length=PRED_LEN,\n",
    "    \n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    \n",
    "    time_varying_unknown_categoricals = [],\n",
    "    time_varying_unknown_reals = [],\n",
    "\n",
    "\n",
    "    time_varying_known_categoricals=known_varying_categorical_cols,\n",
    "    time_varying_known_reals=known_varying_reals_cols,\n",
    "    \n",
    "    target_normalizer=GroupNormalizer(groups=[G_SYM], method=\"standard\"),\n",
    "    \n",
    "    allow_missing_timesteps=True,\n",
    "    \n",
    "    scalers= {name: None for name in (unscaler_cols)}\n",
    ")\n",
    "\n",
    "val_ds = TimeSeriesDataSet.from_dataset(\n",
    "    train_ds,\n",
    "    df_val_ctx,\n",
    "    min_prediction_idx=val_start_idx,\n",
    "    predict=False,\n",
    "    stop_randomization=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb8f0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 419800, val samples: 68928\n",
      "train_loader batches = 655\n",
      "val_loader batches = 270\n",
      "[2025-10-23 15:48:09] data loaders ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# é…ç½®ï¼šæ¯ä¸ª epoch æƒ³è®­ç»ƒå¤šå°‘ä¸ªâ€œæ ·æœ¬/çª—å£â€\n",
    "# ä»»é€‰å…¶ä¸€ï¼šæŒ‰æ¯”ä¾‹æˆ–å›ºå®šæ•°é‡\n",
    "SAMPLE_FRACTION = 0.1        # ä¾‹ï¼šæ¯ä¸ª epoch åªéšæœºæŠ½å– 20% çš„çª—å£\n",
    "# SAMPLES_PER_EPOCH = 10000  # æˆ–è€…ï¼šå›ºå®šæ¯ä¸ª epoch æŠ½ 1e4 ä¸ªçª—å£\n",
    "\n",
    "# è®¡ç®— num_samplesï¼ˆå³æœ¬ epoch çš„æ ·æœ¬æ•°ï¼‰\n",
    "_train_total = len(train_ds); _val_total = len(val_ds)\n",
    "num_samples = max(1, int(_train_total * SAMPLE_FRACTION))\n",
    "# å¦‚æœç”¨å›ºå®šæ•°é‡å°±æ”¹ä¸ºï¼š\n",
    "# num_samples = min(_train_total, SAMPLES_PER_EPOCH)\n",
    "\n",
    "# æ‰“å°epoch æ ·æœ¬æ•°\n",
    "print(f\"train samples: {_train_total}, val samples: {_val_total}\")\n",
    "\n",
    "# å…³é”®ï¼šå¸¦æ”¾å›çš„éšæœºé‡‡æ ·å™¨ï¼ˆæ¯ä¸ª epoch éƒ½ä¼šé‡æ–°æŠ½æ ·ï¼‰\n",
    "train_sampler = RandomSampler(train_ds, replacement=True, num_samples=num_samples)\n",
    "\n",
    "train_loader = train_ds.to_dataloader(train=True, batch_size=BATCH_SIZE, num_workers=12, pin_memory=True, persistent_workers=True, prefetch_factor=2, shuffle=False,sampler=train_sampler)\n",
    "val_loader   = val_ds.to_dataloader(train=False, batch_size=BATCH_SIZE*4, num_workers=12, pin_memory=True, persistent_workers=True, prefetch_factor=2, shuffle=False)\n",
    "\n",
    "del df, df_train, df_val_ctx; gc.collect()\n",
    "\n",
    "n_train_batches = len(train_loader)\n",
    "print(f\"train_loader batches = {n_train_batches}\")\n",
    "n_val_batches = len(val_loader)\n",
    "print(f\"val_loader batches = {n_val_batches}\")\n",
    "\n",
    "print(f\"[{_now()}] data loaders ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cf6b4",
   "metadata": {},
   "source": [
    "## ä¼˜åŒ–å­¦ä¹ ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10edb80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:33<00:00,  5.71s/it]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:34<00:00,  5.75s/it]\n",
      "Restoring states from the checkpoint path at /home/admin_ml/Jackson/projects/js/JS/.lr_find_dbb94835-07d1-44aa-910a-9bdc46c4ff52.ckpt\n",
      "Restored all states from the checkpoint at /home/admin_ml/Jackson/projects/js/JS/.lr_find_dbb94835-07d1-44aa-910a-9bdc46c4ff52.ckpt\n",
      "Learning rate set to 1.1220184543019633e-05\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "pl.set_random_seed(42)\n",
    "\n",
    "# 1) è¿è¡Œå‰æ¸…ç†ç¼“å­˜ï¼ˆå¯é€‰ï¼‰\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# 2) ç»™ LR finder ä¸“ç”¨çš„å° batch loader\n",
    "#    ä¸è¦åŠ¨æ­£å¼çš„ train_loader/val_loader\n",
    "# 3) æ··åˆç²¾åº¦ï¼ˆä¼˜å…ˆ bf16ï¼Œå…¶æ¬¡ fp16ï¼‰\n",
    "trainer_lr = lp.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "# 4) å¯é€‰ï¼šåªä¸º LR finder æ„å»ºä¸€ä¸ªâ€œè½»é‡åŒ–â€çš„ TFTï¼ˆä¸å½±å“æ­£å¼æ¨¡å‹ï¼‰\n",
    "tft_lr = TemporalFusionTransformer.from_dataset(\n",
    "    train_ds,\n",
    "    learning_rate=LR,\n",
    "    hidden_size=32,             # é™ä½ä¸€ç‚¹éšè—ç»´åº¦\n",
    "    attention_head_size=1,       # é™ä½å¤´æ•°\n",
    "    hidden_continuous_size=16,\n",
    "    dropout=0.2,\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"ranger\",\n",
    ")\n",
    "\n",
    "# 5) è¿è¡Œ LR finderï¼Œé™åˆ¶æœç´¢æ­¥æ•°\n",
    "res = Tuner(trainer_lr).lr_find(\n",
    "    tft_lr,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e-1,         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2237c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 1.1220184543019633e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d5322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a850949c",
   "metadata": {},
   "source": [
    "## æ­£å¼è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c42bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-2  # æ ¹æ® LR finder ç»“æœè°ƒæ•´\n",
    "HIDDEN = 32\n",
    "HEADS = 1\n",
    "DROPOUT = 0.1\n",
    "MAX_EPOCHS = 5\n",
    "GCV = 0.1\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_ds,\n",
    "    learning_rate=LR,\n",
    "    hidden_size=HIDDEN,\n",
    "    attention_head_size=HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    hidden_continuous_size=HIDDEN//2,\n",
    "    loss=QuantileLoss(quantiles=[0.5]),                            # ç‚¹é¢„æµ‹ OKï¼Œä¼šè‡ªåŠ¨ç”¨ weight                     \n",
    "    optimizer=\"ranger\",\n",
    "    reduce_on_plateau_patience=1,\n",
    "    reduce_on_plateau_min_lr=1e-5\n",
    ")\n",
    "# æ‰“å°æ¨¡å‹å‚æ•°\n",
    "print(f\"fold_id = {fold_id}\")\n",
    "print(f\"train_lo = {train_lo}, train_hi = {train_hi}\")\n",
    "print(f\"val_lo = {val_lo}, val_hi = {val_hi}\")\n",
    "print(f\"target_col = {TARGET_COL}\")\n",
    "print(f\"weight_col = {WEIGHT_COL}\")\n",
    "print(f\"encode length = {ENC_LEN}, pred length = {PRED_LEN}\")\n",
    "print(f\"lr = {LR}, batch size = {BATCH_SIZE}\")\n",
    "print(f\"hiden size = {HIDDEN}, heads = {HEADS}, dropout = {DROPOUT}\")\n",
    "print(f\"max epochs = {MAX_EPOCHS}\")\n",
    "\n",
    "\n",
    "ckpt_dir_fold = Path(CKPTS_DIR) / f\"fold_{fold_id}\"\n",
    "ckpt_dir_fold.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_NAME = f\"ranger_lr{LR:g}_bs{BATCH_SIZE}_enc{ENC_LEN}_hidden{HIDDEN}_heads{HEADS}_time_{ts}\"\n",
    "TEMP_LOG_DIR = Path(\"./tft_logs\"); TEMP_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "logger = TensorBoardLogger(save_dir=TEMP_LOG_DIR.as_posix(),name=\"tft\",version=RUN_NAME,default_hp_metric=False)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3), \n",
    "            LearningRateMonitor()\n",
    "            ] \n",
    "\n",
    "trainer = lp.Trainer(\n",
    "    #fast_dev_run=1,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=GCV,          \n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    check_val_every_n_epoch=1, \n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=callbacks,   # â† è®°å¾—æŠŠ lr_logger æ”¾è¿›æ¥\n",
    "    logger=logger,\n",
    "    # accumulate_grad_batches=2,     # æ˜¾å­˜ç´§å¼ æ—¶å†å¼€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ee5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 26     | train\n",
      "3  | prescalers                         | ModuleDict                      | 6.5 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 0      | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 491 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 491 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 33     | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.122     Total estimated model params size (MB)\n",
      "6042      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 12/1311 [01:10<2:06:35,  0.17it/s, v_num=5-20, train_loss_step=1.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd89e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (js-uv)",
   "language": "python",
   "name": "js-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
