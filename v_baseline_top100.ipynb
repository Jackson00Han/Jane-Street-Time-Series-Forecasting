{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed813b1",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2cac4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-21 17:35:55] imports ok\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── 标准库 ──────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# ── 第三方 ──────────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import lightning as L\n",
    "import lightning.pytorch as lp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline\n",
    "from pytorch_forecasting.metrics import MAE, RMSE\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_forecasting.data import TorchNormalizer, GroupNormalizer\n",
    "\n",
    "\n",
    "# 你的工程工具\n",
    "from pipeline.io import cfg, P, fs, storage_options, ensure_dir_local, ensure_dir_az\n",
    "from pipeline.stream_input_local import ShardedBatchStream  \n",
    "from pipeline.wr2 import WR2\n",
    "\n",
    "# ---- 性能/兼容开关（仅一次）----\n",
    "os.environ.setdefault(\"POLARS_MAX_THREADS\", str(max(1, os.cpu_count() // 2)))\n",
    "pl.enable_string_cache()\n",
    "cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "import time as _t\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "def _now() -> str:\n",
    "    return _t.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"[{_now()}] imports ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a03bfe",
   "metadata": {},
   "source": [
    "# 定义工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856ce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "# 滑动窗划分\n",
    "def make_sliding_cv_by_days(all_days: np.ndarray, *, n_splits: int, gap_days: int, train_to_val: int):\n",
    "    all_days = np.asarray(all_days).ravel()\n",
    "    K, R, G = n_splits, train_to_val, gap_days\n",
    "    usable = len(all_days) - G\n",
    "    if usable <= 0 or K <= 0 or R <= 0:\n",
    "        return []\n",
    "    V_base, rem = divmod(usable, R + K)\n",
    "    if V_base <= 0:\n",
    "        return []\n",
    "    T = R * V_base\n",
    "    v_lens = [V_base + 1 if i < rem else V_base for i in range(K)]\n",
    "    folds, v_lo = [], T + G\n",
    "    for V_i in v_lens:\n",
    "        v_hi, tr_hi, tr_lo = v_lo + V_i, v_lo - G, v_lo - G - T\n",
    "        if tr_lo < 0 or v_hi > len(all_days):\n",
    "            break\n",
    "        folds.append((all_days[tr_lo:tr_hi], all_days[v_lo:v_hi]))\n",
    "        v_lo = v_hi\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a432b",
   "metadata": {},
   "source": [
    "# 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4040fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = (1400, 1600)  # 仅用于本次实验\n",
    "\n",
    "# 读入筛选的所有特征列\n",
    "\n",
    "path = Path(\"/mnt/data/js/exp/v1/models/tune/selected_covariant_features.txt\")\n",
    "filted_cols = path.read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "selected_features = pd.read_csv(\"/mnt/data/js/exp/v1/models/tune/feature_importance__fixed__fixed__mm_full_train__features__fs__1400-1698__cv2-g7-r4__seed42__top1000__1760906660__range830-1698__range830-1698__cv2-g7-r4__1760912739.csv\")\n",
    "\n",
    "df_cov_cols = selected_features[selected_features['feature'].isin(filted_cols)].copy()\n",
    "\n",
    "# 我们这里重新归一化一下\n",
    "df_cov_cols[\"mean_gain\"] = (df_cov_cols['mean_gain'] / df_cov_cols['mean_gain'].sum()).astype(np.float32)\n",
    "df_e_features = df_cov_cols.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========== 1) 初始化配置 ==========\n",
    "\n",
    "# 所有列\n",
    "G_SYM, G_DATE, G_TIME = cfg[\"keys\"]          # e.g. (\"symbol_id\",\"date_id\",\"time_id\")\n",
    "TARGET_COL = cfg[\"target\"]                   # e.g. \"responder_6\"\n",
    "WEIGHT_COL = cfg[\"weight\"]                   # 允许为 None\n",
    "\n",
    "TIME_FEATURES = [\"time_bucket\", \"time_pos\", \"time_sin\", \"time_cos\"]\n",
    "COV_FEATURES = df_e_features['feature'].iloc[:100].tolist() # 可能含有组内常数列\n",
    "\n",
    "STATIC_FEATURES = [c for c in COV_FEATURES if c in [\"feature_09\", \"feature_10\", \"feature_11\"]]\n",
    "\n",
    "CS_RANK_FEATURES = [c for c in COV_FEATURES if c.endswith(\"__csrank\")]\n",
    "\n",
    "CS_R_Z_FEATURES = [c for c in COV_FEATURES if c.endswith(\"__cs_z\") or c.endswith(\"__rz\")]\n",
    "\n",
    "\n",
    "do_z_co_cols = [c for c in COV_FEATURES if c not in STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config] ready\n"
     ]
    }
   ],
   "source": [
    "# 训练 & CV 超参\n",
    "N_SPLITS     = 1\n",
    "GAP_DAYS     = 0\n",
    "TRAIN_TO_VAL = 8\n",
    "ENC_LEN      = 50\n",
    "DEC_LEN      = 1\n",
    "PRED_LEN     = DEC_LEN\n",
    "BATCH_SIZE   = 512\n",
    "LR           = 2e-3\n",
    "HIDDEN       = 64\n",
    "HEADS        = 2\n",
    "DROPOUT      = 0.2\n",
    "MAX_EPOCHS   = 30\n",
    "\n",
    "# 数据路径\n",
    "PANEL_DIR_AZ   = P(\"az\", cfg[\"paths\"].get(\"panel_shards\", \"panel_shards\"))\n",
    "\n",
    "TFT_LOCAL_ROOT = P(\"local\", \"tft\"); ensure_dir_local(TFT_LOCAL_ROOT)\n",
    "\n",
    "LOCAL_CLEAN_DIR = f\"{TFT_LOCAL_ROOT}/clean\"; ensure_dir_local(LOCAL_CLEAN_DIR)\n",
    "CKPTS_DIR = Path(TFT_LOCAL_ROOT) / \"ckpts\"; ensure_dir_local(CKPTS_DIR.as_posix())\n",
    "LOGS_DIR  = Path(TFT_LOCAL_ROOT) / \"logs\";  ensure_dir_local(LOGS_DIR.as_posix())\n",
    "\n",
    "\n",
    "print(\"[config] ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46945dbf",
   "metadata": {},
   "source": [
    "# 导入数据，添加全局time_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917caa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = fs.glob(\"az://jackson/js_exp/exp/v1/panel_shards/*.parquet\")\n",
    "data_paths =[f\"az://{p}\" for p in data_paths]\n",
    "\n",
    "lf_data = (\n",
    "    pl.scan_parquet(data_paths, storage_options=storage_options)\n",
    "    .select([*cfg['keys'], WEIGHT_COL, TARGET_COL, *TIME_FEATURES, *COV_FEATURES])\n",
    "    .filter(pl.col(G_DATE).is_between(start_date, end_date, closed=\"both\"))\n",
    ")\n",
    "lf_data = lf_data.sort([G_SYM, G_DATE, G_TIME])\n",
    "\n",
    "\n",
    "# 先归一化time_pos\n",
    "lf_data = lf_data.with_columns(\n",
    "    (pl.col(\"time_pos\") / pl.lit(968)).cast(pl.Float32).alias(\"time_pos\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c37451",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = (\n",
    "    lf_data.select([G_DATE, G_TIME]).unique()\n",
    "        .sort([G_DATE, G_TIME])\n",
    "        .with_row_index(\"time_idx\")\n",
    "        .with_columns(pl.col(\"time_idx\").cast(pl.Int64))\n",
    "        .collect(streaming=True)\n",
    ")\n",
    "\n",
    "container_prefix = \"az://jackson/js_exp/exp/v1/tft/panel_clean_shards\"; ensure_dir_az(container_prefix)\n",
    "chunk_size = 30\n",
    "for lo in range(start_date, end_date + 1, chunk_size):\n",
    "    hi = min(lo + chunk_size - 1, end_date)\n",
    "    print(f\"processing date range: {lo} ~ {hi}\")\n",
    "    \n",
    "    lf_chunk = lf_data.filter(pl.col(G_DATE).is_between(lo, hi, closed=\"both\"))\n",
    "    \n",
    "    lf_grid_chunk = (\n",
    "        grid_df.lazy().filter(pl.col(G_DATE).is_between(lo, hi, closed=\"both\"))\n",
    "    )\n",
    "    \n",
    "    lf_joined = (\n",
    "        lf_chunk.join(lf_grid_chunk, on=[G_DATE, G_TIME], how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "    )\n",
    "    \n",
    "    out_path = f\"{container_prefix}/panel_clean_{lo:04d}_{hi:04d}.parquet\"\n",
    "    print(f\"writing to: {out_path}\")\n",
    "    \n",
    "    lf_joined.sink_parquet(\n",
    "        out_path,\n",
    "        storage_options=storage_options,\n",
    "        compression=\"zstd\",\n",
    "    )\n",
    "    \n",
    "del lf_data, lf_chunk, lf_grid_chunk, lf_joined; gc.collect()\n",
    "print(f\"[{_now()}] all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6633f",
   "metadata": {},
   "source": [
    "# 重新导入含有time_idx的数据 & CV 划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daec9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_prefix = \"az://jackson/js_exp/exp/v1/tft/panel_clean_shards\"\n",
    "data_paths = fs.glob(f\"{container_prefix}/*.parquet\")\n",
    "data_paths = [f\"az://{p}\" for p in data_paths] \n",
    "lf_with_idx = pl.scan_parquet(data_paths, storage_options=storage_options).filter(pl.col(G_DATE).is_between(start_date, end_date, closed=\"both\")).sort([G_SYM, \"time_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63da710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cv] total 1 folds\n",
      "[(array([1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410,\n",
      "       1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421,\n",
      "       1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432,\n",
      "       1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443,\n",
      "       1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454,\n",
      "       1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465,\n",
      "       1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476,\n",
      "       1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487,\n",
      "       1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498,\n",
      "       1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509,\n",
      "       1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520,\n",
      "       1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531,\n",
      "       1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542,\n",
      "       1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553,\n",
      "       1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564,\n",
      "       1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575],\n",
      "      dtype=int32), array([1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586,\n",
      "       1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597,\n",
      "       1598], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "# ==========  CV 划分 ==========\n",
    "all_days = (\n",
    "    lf_with_idx.select(pl.col(G_DATE)).unique().sort([G_DATE])\n",
    "    .collect(streaming=True)[G_DATE].to_numpy()\n",
    ")\n",
    "folds_by_day = make_sliding_cv_by_days(all_days, n_splits=N_SPLITS, gap_days=GAP_DAYS, train_to_val=TRAIN_TO_VAL)\n",
    "\n",
    "print(f\"[cv] total {len(folds_by_day)} folds\")\n",
    "\n",
    "assert len(folds_by_day) > 0, \"no CV folds constructed\"\n",
    "print(folds_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff439b97",
   "metadata": {},
   "source": [
    "# 接下来均已第一折为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e614fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "统计标准化使用训练集的日期范围 = 1400 ~ 1575\n",
      "验证集日期范围 = 1576 ~ 1598\n"
     ]
    }
   ],
   "source": [
    "fold_id = 0\n",
    "# 取第一个 fold 的训练集最后一天，作为本折统计 z-score 的上界\n",
    "train_lo, train_hi = folds_by_day[fold_id][0][0], folds_by_day[fold_id][0][-1]\n",
    "val_lo, val_hi = folds_by_day[fold_id][1][0], folds_by_day[fold_id][1][-1]\n",
    "\n",
    "print(f\"统计标准化使用训练集的日期范围 = {train_lo} ~ {train_hi}\")\n",
    "print(f\"验证集日期范围 = {val_lo} ~ {val_hi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0689de",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d547d97",
   "metadata": {},
   "source": [
    "## 填补因为特征工程产生的缺失列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练集的各特征量的中位数\n",
    "lf_tr = lf_with_idx.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "\n",
    "grp_median = (\n",
    "    lf_tr\n",
    "    .group_by([G_SYM, \"time_pos\"])\n",
    "    .agg([\n",
    "        pl.col(col).median().alias(f\"{col}_median_st\") for col in COV_FEATURES\n",
    "    ])\n",
    "    .sort([G_SYM, \"time_pos\"])\n",
    ")\n",
    "\n",
    "glb_median = (\n",
    "    lf_tr\n",
    "    .group_by(\"time_pos\")\n",
    "    .agg([\n",
    "        pl.col(col).median().alias(f\"{col}_median_t\") for col in COV_FEATURES\n",
    "    ])\n",
    "    .sort(\"time_pos\")\n",
    ")\n",
    "\n",
    "# 应用于本折全部数据 trian + val\n",
    "lf_all = lf_with_idx.join(grp_median, on=[G_SYM, \"time_pos\"], how=\"left\").join(glb_median, on=[\"time_pos\"], how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "# 逐列用中位数替换缺失值\n",
    "fill_exprs = []\n",
    "\n",
    "for col in COV_FEATURES:\n",
    "    fill_exprs.append(\n",
    "        pl.coalesce([\n",
    "            pl.col(col),\n",
    "            pl.col(f\"{col}_median_st\"),\n",
    "            pl.col(f\"{col}_median_t\")\n",
    "        ]).alias(col)\n",
    "    )\n",
    "\n",
    "lf_all_imputed = lf_all.with_columns(fill_exprs)\n",
    "\n",
    "# 去掉中位数列\n",
    "drop_cols = [f\"{col}_median_st\" for col in COV_FEATURES]\n",
    "drop_cols += [f\"{col}_median_t\" for col in COV_FEATURES]\n",
    "lf_all_imputed = lf_all_imputed.drop(drop_cols)\n",
    "\n",
    "df_null_lf_all_imputed = lf_all_imputed.select(\n",
    "    pl.all().null_count()\n",
    ").collect().to_pandas().T.sort_values(by=0, ascending=False)\n",
    "\n",
    "assert df_null_lf_all_imputed.iloc[0,0] == 0, \"仍有缺失值未填补完成！\"\n",
    "\n",
    "del lf_tr, grp_median, glb_median, lf_all, df_null_lf_all_imputed; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89886d48",
   "metadata": {},
   "source": [
    "## 静态特征归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a20f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_tr_imputed = lf_all_imputed.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "\n",
    "static_glb_minmax = (\n",
    "    lf_tr_imputed.select(\n",
    "        *[pl.col(c).min().alias(f\"{c}_min\") for c in STATIC_FEATURES],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max\") for c in STATIC_FEATURES],\n",
    "    ).collect().to_dicts()[0]   # ← 用 to_dicts()[0]\n",
    ")\n",
    "\n",
    "eps = 1e-8\n",
    "\n",
    "lf_all = lf_all_imputed.with_columns([\n",
    "    (\n",
    "        ((pl.col(c) - pl.lit(static_glb_minmax[f\"{c}_min\"])) /\n",
    "         (pl.lit(static_glb_minmax[f\"{c}_max\"] - static_glb_minmax[f\"{c}_min\"]) + eps))\n",
    "        .clip(0.0, 1.0)\n",
    "    ).cast(pl.Float32).alias(c)   # ← cast/alias 作用于“整个结果”\n",
    "    for c in STATIC_FEATURES\n",
    "])\n",
    "\n",
    "# 不需要 drop（你没创建 *_glb_min/_glb_max 列）\n",
    "del lf_tr_imputed, static_glb_minmax; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b2784",
   "metadata": {},
   "source": [
    "## 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Z-score ==========\n",
    "# 计算 训练集 stats\n",
    "\n",
    "lf_tr = lf_all.filter(pl.col(G_DATE).is_between(train_lo, train_hi, closed=\"both\"))\n",
    "grp_stats = (\n",
    "    lf_tr\n",
    "    .group_by(G_SYM)\n",
    "    .agg([pl.col(c).mean().alias(f\"mu_grp_{c}\") for c in do_z_co_cols] +\n",
    "        [pl.col(c).std().alias(f\"std_grp_{c}\") for c in do_z_co_cols])\n",
    ").collect(streaming=True)\n",
    "\n",
    "glb_stats = (\n",
    "    lf_tr\n",
    "    .select([pl.col(c).mean().alias(f\"mu_glb_{c}\") for c in do_z_co_cols] +\n",
    "            [pl.col(c).std().alias(f\"std_glb_{c}\") for c in do_z_co_cols])\n",
    ").collect(streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb73a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "glb_row = glb_stats.to_dicts()[0]\n",
    "\n",
    "# 逐日标准化本折所有数据并保存\n",
    "fold_root = f\"az://jackson/js_exp/exp/v1/tft/fold_{fold_id}\"; ensure_dir_az(fold_root)\n",
    "z_prefix = f\"{fold_root}/z_shards\"; ensure_dir_az(z_prefix)\n",
    "\n",
    "z_done_cols = [f\"z_{c}\" for c in (do_z_co_cols)]\n",
    "min_std = 1e-5\n",
    "eps = 1e-8\n",
    "\n",
    "# 预处理全局均值/方差的兜底，避免在行级判断\n",
    "glb_mu = {c: glb_row[f\"mu_glb_{c}\"] for c in do_z_co_cols}\n",
    "glb_std = {}\n",
    "for c in do_z_co_cols:\n",
    "    s = glb_row[f\"std_glb_{c}\"]\n",
    "    if s is None or s <= 0:\n",
    "        s = min_std\n",
    "    glb_std[c] = s\n",
    "\n",
    "for d in range(train_lo, val_hi + 1):\n",
    "    lf_day = lf_all.filter(pl.col(G_DATE) == d)\n",
    "\n",
    "    lf_day_z = lf_day.join(grp_stats.lazy(), on=G_SYM, how=\"left\").sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "    # 1) 先把所有“常量”变成具名列，避免 anonymous literal\n",
    "    const_exprs = []\n",
    "    for c in do_z_co_cols:\n",
    "        const_exprs += [\n",
    "            pl.lit(glb_mu[c]).alias(f\"__mu_glb_{c}\"),\n",
    "            pl.lit(glb_std[c] if glb_std[c] > 0 else min_std).alias(f\"__std_glb_{c}\"),\n",
    "        ]\n",
    "    lf_day_z = lf_day_z.with_columns(const_exprs)\n",
    "\n",
    "    # 2) 计算 z，并用 clip 裁剪\n",
    "    exprs = []\n",
    "    for c in do_z_co_cols:\n",
    "        mu_grp  = pl.col(f\"mu_grp_{c}\")\n",
    "        std_grp = pl.col(f\"std_grp_{c}\")\n",
    "        mu_use = pl.coalesce([mu_grp, pl.col(f\"__mu_glb_{c}\")]).cast(pl.Float32)\n",
    "\n",
    "        std_tmp = pl.when(std_grp.is_null() | (std_grp <= 0))\\\n",
    "                    .then(pl.col(f\"__std_glb_{c}\"))\\\n",
    "                    .otherwise(std_grp)\n",
    "        std_use = pl.when(std_tmp < min_std).then(min_std).otherwise(std_tmp).cast(pl.Float32)\n",
    "\n",
    "        z = ((pl.col(c).cast(pl.Float32) - mu_use) / (std_use + eps)).clip(-3.0, 3.0).alias(f\"z_{c}\")\n",
    "        exprs.append(z)\n",
    "\n",
    "    lf_day_z = lf_day_z.with_columns(exprs)\n",
    "    \n",
    "    keep = [\n",
    "        \"time_idx\", G_SYM, G_DATE, G_TIME, WEIGHT_COL, TARGET_COL\n",
    "    ] + TIME_FEATURES + STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES + z_done_cols\n",
    "        \n",
    "\n",
    "    # 去重但保持顺序（避免 DuplicateError）\n",
    "    keep = list(dict.fromkeys(keep))\n",
    "    \n",
    "    lf_out = lf_day_z.select(keep).sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "    out_path = f\"{z_prefix}/z_{d:04d}.parquet\"\n",
    "    lf_out.collect(streaming=True).write_parquet(\n",
    "        out_path, storage_options=storage_options, compression=\"zstd\"\n",
    "    )\n",
    "    print(f\"wrote z-scored data for day {d} to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b3677",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04668e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight col: weight\n",
      "target cols: responder_6\n",
      "encode length: 50, pred length: 1\n",
      "input varying_reals_cols: ['time_pos', 'time_sin', 'time_cos', 'feature_09', 'feature_60__csrank', 'feature_26__csrank', 'feature_60__cs_z', 'feature_59__cs_z', 'z_feature_06', 'z_feature_36', 'z_feature_04', 'z_feature_59__rstd30', 'z_feature_07', 'z_feature_61__ret50', 'z_feature_31__lag4840', 'z_feature_61__lag7744', 'z_feature_61__diff50', 'z_feature_51__ewm10', 'z_feature_61__lag1936', 'z_feature_59__ewm5', 'z_feature_48', 'z_feature_61__lag900', 'z_feature_59', 'z_feature_51__rmean14', 'z_feature_31__diff50', 'z_feature_04__ewm5', 'z_feature_61__lag3872', 'z_feature_04__ewm10', 'z_feature_06__rz30', 'z_feature_60__rstd30', 'z_feature_54__ewm10', 'z_feature_37__rstd30', 'z_feature_22__diff50', 'z_feature_30__lag50', 'z_feature_01__ewm50', 'z_feature_61__lag4840', 'z_feature_61__lag2904', 'z_responder_2_prev_tail_lag10', 'z_feature_26__lag900', 'z_feature_08__ewm50', 'z_feature_20__diff50', 'z_feature_04__ewm50', 'z_responder_5_prevday_mean', 'z_feature_31__lag1936', 'z_feature_75__rstd7', 'z_feature_58__ewm50', 'z_feature_43__ewm50', 'z_feature_25__diff50', 'z_feature_30__lag968', 'z_feature_40__ewm10', 'z_responder_7_close_roll14_std', 'z_responder_8_prevday_mean', 'z_feature_61__lag6776', 'z_responder_7_prev_tail_lag967', 'z_responder_6_prevday_std', 'z_feature_38__lag100', 'z_feature_26__diff50', 'z_feature_76__rstd14', 'z_feature_55__ewm50', 'z_feature_52__rstd30', 'z_feature_61__lag5808', 'z_responder_3_prevday_std', 'z_feature_26__lag6776', 'z_feature_06__ewm10', 'z_responder_8_prev_tail_lag967', 'z_feature_07__rmean3', 'z_feature_75__rstd3', 'z_feature_08__rmean30', 'z_feature_08__lag100', 'z_feature_30__diff50', 'z_feature_25__ret50', 'z_feature_42__rmean30', 'z_feature_21__diff50', 'z_feature_59__ewm50', 'z_responder_6_prev_tail_lag967', 'z_feature_07__rmean30', 'z_feature_24__lag4840', 'z_feature_38__ewm50', 'z_feature_68__ewm10', 'z_feature_30__lag3872', 'z_feature_05__rstd30', 'z_feature_42__ewm50', 'z_feature_45__ewm5', 'z_feature_24__diff50', 'z_feature_31__ret50', 'z_feature_05__rmean30', 'z_feature_23__diff50', 'z_responder_6_prev_tail_lag50', 'z_feature_59__rstd14', 'z_feature_21__lag900', 'z_feature_06__rmean14', 'z_feature_21__ret50', 'z_feature_54__rmean14', 'z_feature_05__ewm50', 'z_feature_23__ret50', 'z_feature_58', 'z_feature_53__ewm50', 'z_feature_24', 'z_feature_47__rstd30', 'z_feature_33__rmean3', 'z_feature_61__lag500', 'z_feature_27__ret50', 'z_feature_51__ewm50']\n",
      "input varying_categorical_cols: ['time_bucket', 'gap_flag']\n"
     ]
    }
   ],
   "source": [
    "lp.seed_everything(42) \n",
    "\n",
    "z_done_cols = [f\"z_{c}\" for c in do_z_co_cols]\n",
    "\n",
    "# 明确输入的各列\n",
    "known_varying_categorical_cols = [\"time_bucket\", \"gap_flag\"] # gap_flag 需要后续添加\n",
    "\n",
    "known_varying_reals_cols = [\"time_pos\", \"time_sin\", \"time_cos\"] + STATIC_FEATURES + CS_RANK_FEATURES + CS_R_Z_FEATURES + z_done_cols\n",
    "unscaler_cols = known_varying_reals_cols\n",
    "\n",
    "TRAIN_COLS = [G_SYM, G_DATE, G_TIME, \"time_idx\", WEIGHT_COL, TARGET_COL] + known_varying_categorical_cols + known_varying_reals_cols \n",
    "\n",
    "print(f\"weight col: {WEIGHT_COL}\")\n",
    "print(f\"target cols: {TARGET_COL}\")\n",
    "print(f\"encode length: {ENC_LEN}, pred length: {PRED_LEN}\")\n",
    "print(f\"input varying_reals_cols: {known_varying_reals_cols}\")\n",
    "print(f\"input varying_categorical_cols: {known_varying_categorical_cols}\")\n",
    "\n",
    "\n",
    "# 导入 本折z-score 后的数据进行后续处理\n",
    "fold_root = f\"az://jackson/js_exp/exp/v1/tft/fold_{fold_id}\"\n",
    "z_prefix = f\"{fold_root}/z_shards\"\n",
    "\n",
    "data_paths = fs.glob(f\"{z_prefix}/*.parquet\")\n",
    "data_paths = [f\"az://{p}\" for p in data_paths]\n",
    "lf = pl.scan_parquet(data_paths, storage_options=storage_options).sort([G_SYM, \"time_idx\"])\n",
    "\n",
    "# 添加 gap_flag 列\n",
    "lf = lf.with_columns(\n",
    "    pl.col(\"time_idx\").diff().over(G_SYM).fill_null(1).alias(\"time_delta\")\n",
    ").with_columns(\n",
    "    (pl.col(\"time_delta\") > 1).alias(\"gap_flag\")\n",
    ").drop(\"time_delta\")\n",
    "\n",
    "lf = lf.select(TRAIN_COLS)\n",
    "\n",
    "df = lf.collect(streaming=True).to_pandas()\n",
    "df[G_SYM] = df[G_SYM].astype(str).astype(\"category\")\n",
    "\n",
    "# 确保 pandas dtypes\n",
    "for c in known_varying_categorical_cols:\n",
    "    df[c] = df[c].astype(str).astype(\"category\")\n",
    "\n",
    "for c in known_varying_reals_cols:\n",
    "    df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    \n",
    "df[TARGET_COL] = df[TARGET_COL].astype(np.float32)\n",
    "df[WEIGHT_COL] = df[WEIGHT_COL].astype(np.float32)\n",
    "\n",
    "df.sort_values(by=[G_SYM, \"time_idx\"], inplace=True)\n",
    "\n",
    "\n",
    "train_start_idx = df[df[G_DATE] == train_lo][\"time_idx\"].min()\n",
    "train_end_idx   = df[df[G_DATE] == train_hi][\"time_idx\"].max()\n",
    "val_start_idx   = df[df[G_DATE] == val_lo][\"time_idx\"].min()\n",
    "val_end_idx     = df[df[G_DATE] == val_hi][\"time_idx\"].max()\n",
    "\n",
    "df_train = df.loc[df.time_idx.between(train_start_idx, train_end_idx)].copy()\n",
    "\n",
    "warmup_len = ENC_LEN\n",
    "df_val_ctx   = df.loc[df.time_idx.between(val_start_idx-warmup_len, val_end_idx)].copy()\n",
    "\n",
    "df_train[\"time_idx\"] = df_train[\"time_idx\"].astype(\"int64\")\n",
    "df_val_ctx[\"time_idx\"]   = df_val_ctx[\"time_idx\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8f0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-21 17:37:15] data loaders ready\n"
     ]
    }
   ],
   "source": [
    "train_ds = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=TARGET_COL,\n",
    "    group_ids=[G_SYM],\n",
    "    weight=WEIGHT_COL,\n",
    "    min_encoder_length=ENC_LEN // 2,\n",
    "    max_encoder_length=ENC_LEN,\n",
    "    min_prediction_length=PRED_LEN,\n",
    "    max_prediction_length=PRED_LEN,\n",
    "    \n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    \n",
    "    time_varying_unknown_categoricals = [],\n",
    "    time_varying_unknown_reals = [],\n",
    "\n",
    "\n",
    "    time_varying_known_categoricals=known_varying_categorical_cols,\n",
    "    time_varying_known_reals=known_varying_reals_cols,\n",
    "    \n",
    "    target_normalizer=TorchNormalizer(method=\"standard\"),\n",
    "    \n",
    "    allow_missing_timesteps=True,\n",
    "    \n",
    "    add_relative_time_idx=False,\n",
    "    add_target_scales=False,\n",
    "    add_encoder_length=False,\n",
    "    \n",
    "    scalers={name: None for name in (unscaler_cols)}\n",
    ")\n",
    "\n",
    "\n",
    "val_ds = TimeSeriesDataSet.from_dataset(\n",
    "    train_ds,\n",
    "    df_val_ctx,\n",
    "    predict=False,\n",
    "    stop_randomization=True,\n",
    ")\n",
    "\n",
    "train_loader = train_ds.to_dataloader(train=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "val_loader   = val_ds.to_dataloader(train=False, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "del df, df_train, df_val_ctx; gc.collect()\n",
    "print(f\"[{_now()}] data loaders ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb999c",
   "metadata": {},
   "source": [
    "## TFT 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cf6b4",
   "metadata": {},
   "source": [
    "## 优化学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "\n",
    "# 1) 运行前清理缓存（可选）\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# 2) 给 LR finder 专用的小 batch loader\n",
    "#    不要动正式的 train_loader/val_loader\n",
    "BATCH_LR_FIND = max(1, BATCH_SIZE // 4)  # 比正式 batch 小 4 倍\n",
    "train_loader_lr = train_ds.to_dataloader(train=True,  batch_size=BATCH_LR_FIND, num_workers=4)\n",
    "val_loader_lr   = val_ds.to_dataloader(  train=False, batch_size=BATCH_LR_FIND*2, num_workers=4)\n",
    "\n",
    "# 3) 混合精度（优先 bf16，其次 fp16）\n",
    "trainer_lr = lp.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=32,\n",
    "    gradient_clip_val=0.1,\n",
    "    # 只跑很小的子集，避免显存飙升\n",
    "    limit_train_batches=50,   # 只取 50 个 batch（可再小）\n",
    "    limit_val_batches=10,\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "\n",
    "# 4) 可选：只为 LR finder 构建一个“轻量化”的 TFT（不影响正式模型）\n",
    "tft_lr = TemporalFusionTransformer.from_dataset(\n",
    "    train_ds,\n",
    "    learning_rate=LR,\n",
    "    hidden_size=min(HIDDEN, 64),             # 降低一点隐藏维度\n",
    "    attention_head_size=min(HEADS, 2),       # 降低头数\n",
    "    hidden_continuous_size=min(HIDDEN//2, 32),\n",
    "    dropout=DROPOUT,\n",
    "    loss=RMSE(),\n",
    "    logging_metrics=[],\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer_params={\"weight_decay\": 1e-4},\n",
    "    reduce_on_plateau_patience=3,\n",
    "    # 如果你不让模型看历史 y：\n",
    "    # use_encoder_target=False,\n",
    ")\n",
    "\n",
    "# 5) 运行 LR finder，限制搜索步数\n",
    "res = Tuner(trainer_lr).lr_find(\n",
    "    tft_lr,\n",
    "    train_dataloaders=train_loader_lr,\n",
    "    val_dataloaders=val_loader_lr,\n",
    "    min_lr=1e-6,\n",
    "    max_lr=1e-2,           # 上界别设到 10，TFT 通常 1e-3~1e-2\n",
    "    num_training=150,      # 最多 150 个 step（再小也可以）\n",
    "    mode=\"exponential\",\n",
    "    early_stop_threshold=4.0,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2237c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850949c",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3098bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | RMSE                            | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 26     | train\n",
      "3  | prescalers                         | ModuleDict                      | 6.6 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 0      | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 926 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 926 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K | train\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 12.4 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K  | train\n",
      "20 | output_layer                       | Linear                          | 65     | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.221     Total estimated model params size (MB)\n",
      "3144      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47646f0616ed4ea5ab067b45eac57805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type at::Half without overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 50\u001b[0m\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m lp\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     18\u001b[0m     fast_dev_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     19\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mMAX_EPOCHS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# accumulate_grad_batches=2,     # 显存紧张时再开\u001b[39;00m\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[1;32m     37\u001b[0m     train_ds,\n\u001b[1;32m     38\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mLR,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     reduce_on_plateau_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:560\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:49\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     52\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:598\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    591\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    592\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    594\u001b[0m     ckpt_path,\n\u001b[1;32m    595\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    596\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m )\n\u001b[0;32m--> 598\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1011\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1055\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1055\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:458\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:348\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:177\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    180\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1366\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1337\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \n\u001b[1;32m   1365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1366\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/amp.py:79\u001b[0m, in \u001b[0;36mMixedPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, LBFGS):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# If backward was skipped in automatic optimization (return None), unscaling is not needed\u001b[39;00m\n\u001b[1;32m     82\u001b[0m skip_unscaling \u001b[38;5;241m=\u001b[39m closure_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:329\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 329\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    332\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/base/_base_model.py:716\u001b[0m, in \u001b[0;36mBaseModel.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03mTrain on batch.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    715\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 716\u001b[0m log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/base/_base_model.py:911\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[0;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/_tft.py:637\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    631\u001b[0m attn_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_enrichment(\n\u001b[1;32m    632\u001b[0m     lstm_output,\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_static_context(static_context_enrichment, timesteps),\n\u001b[1;32m    634\u001b[0m )\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# Attention\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_encoder_length\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# query only for predictions\u001b[39;49;00m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attention_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_lengths\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# skip connection over attention\u001b[39;00m\n\u001b[1;32m    647\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attn_gate_norm(\n\u001b[1;32m    648\u001b[0m     attn_output, attn_input[:, max_encoder_length:]\n\u001b[1;32m    649\u001b[0m )\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/sub_modules.py:532\u001b[0m, in \u001b[0;36mInterpretableMultiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    530\u001b[0m qs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_layers[i](q)\n\u001b[1;32m    531\u001b[0m ks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_layers[i](k)\n\u001b[0;32m--> 532\u001b[0m head, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m head_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(head)\n\u001b[1;32m    534\u001b[0m heads\u001b[38;5;241m.\u001b[39mappend(head_dropout)\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Jackson/projects/js/JS/.venv/lib/python3.10/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/sub_modules.py:472\u001b[0m, in \u001b[0;36mScaledDotProductAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    469\u001b[0m     attn \u001b[38;5;241m=\u001b[39m attn \u001b[38;5;241m/\u001b[39m dimension\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(attn)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type at::Half without overflow"
     ]
    }
   ],
   "source": [
    "ckpt_dir_fold = Path(CKPTS_DIR) / f\"fold_{fold_id}\"\n",
    "ckpt_dir_fold.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=10, min_delta=1e-5, verbose=False\n",
    ")\n",
    "ckpt_cb = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", mode=\"min\", save_top_k=1,\n",
    "    dirpath=ckpt_dir_fold.as_posix(),\n",
    "    filename=f\"fold{fold_id}-tft-best-{{epoch:02d}}-{{val_loss:.5f}}\",\n",
    "    save_on_train_epoch_end=False,\n",
    ")\n",
    "lr_logger = LearningRateMonitor()\n",
    "logger = TensorBoardLogger(\"lighting_logs\")\n",
    "\n",
    "trainer = lp.Trainer(\n",
    "    fast_dev_run=1,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,          # 更稳\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    val_check_interval=0.5,         # 或换成 check_val_every_n_epoch=1\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=200,\n",
    "    callbacks=[early_stop, ckpt_cb, lr_logger],   # ← 记得把 lr_logger 放进来\n",
    "    logger=logger,\n",
    "    # accumulate_grad_batches=2,     # 显存紧张时再开\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_ds,\n",
    "    learning_rate=LR,\n",
    "    hidden_size=HIDDEN,\n",
    "    attention_head_size=HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    hidden_continuous_size=HIDDEN // 2,\n",
    "    loss=RMSE(),                            # 点预测 OK，会自动用 weight\n",
    "    logging_metrics=[],                     # 你自定义的 WR2 可另加\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer_params={\"weight_decay\": 1e-4},\n",
    "    reduce_on_plateau_patience=3,\n",
    ")\n",
    "\n",
    "trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (js-uv)",
   "language": "python",
   "name": "js-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
